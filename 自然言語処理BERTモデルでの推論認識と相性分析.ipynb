{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "自然言語処理BERTモデルでの推論認識と相性分析.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otanet/Recognizing_Textual_Entailment/blob/main/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86BERT%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A7%E3%81%AE%E6%8E%A8%E8%AB%96%E8%AA%8D%E8%AD%98%E3%81%A8%E7%9B%B8%E6%80%A7%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXLQgRmnPAhv"
      },
      "source": [
        "# **自然言語処理BERTモデルでの推論認識と相性分析**\n",
        "\n",
        "YouTubeに内容説明の動画：https://youtu.be/dyipetTsZ40\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "RTE(Recognizing Textual Entailment)推論認識の説明\n",
        "\n",
        "RTEとはある前提文と仮説文、二つを与え、前提文から仮説が推論されればYES,そうでなければNOとする判定をシステムで行うタスクです。\n",
        "\n",
        "\n",
        "例えば\n",
        "\n",
        "前提の情報は：  　　　　 人身事故で電車が遅れた。　　\n",
        "\n",
        "仮説：　　　　　　　  　乗客に影響が出た。\n",
        "\n",
        "NLPモデル判定：　　　　 YES\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "推論認識は、質問応答や情報検索など、テキスト情報の内容の理解が必要なタスクにおいて重要です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEZqaFRdOCGG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "17e73497-e9da-4255-ce85-1cdedcea5976"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install mecab-python3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c28rDT0HPCed"
      },
      "source": [
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification,AdamW,BertConfig\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7MpL3VgPF2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ebf1492-e7f7-40cf-da88-0315f327fefb"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "  \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFyJYKJ5QQ2Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2d003573-a563-4110-8f59-674e28eef7eb"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('daigo/bert-base-japanese-sentiment')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
            "  category=FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjiElkQwSQ2x"
      },
      "source": [
        "##  **Tokenizetionとモデルのインプットについて、、、**\n",
        "\n",
        "\n",
        "\n",
        "推論認識はインプットが二つ（前提文情報、仮説文）、あとアウトプットが一つ（判定）です。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1OX3rPNT2FBWTztbHET9vNuh-KUcsrB9U\" width = 50%>\n",
        "\n",
        "\n",
        "また、モデルの形が二つインプットによって、様様なビジネスに応用することができます。\n",
        "\n",
        "例えば：\n",
        "\n",
        "\n",
        "*   二つ事象の相性認識\n",
        "*   物と人の関係認識\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        ">**商品とユーザーは、相性認識の例：**\n",
        "\n",
        "\n",
        ">あるお店\n",
        "* 自己PRでの特徴：\n",
        "  * 濃厚煮干スープが絶品！ 厳選した煮干・魚介と濃厚豚骨スープを合わせた「濃厚煮干中華そば」。\n",
        "\n",
        ">SNSネット上（Facebook, Twitter, Line）にあるコメントのフォロー者\n",
        "* あるコメント：\n",
        "  * 濃くのあるスープで、めちゃくちゃ美味いっ！！豚肉、穂先メンマも相変わらず抜群の美味さ。\n",
        "\n",
        "\n",
        "\n",
        ">ある店とあるユーザーの相性認識によって、人工知能システムでユーザーに相性順で推薦する\n",
        "\n",
        "*また、事象と人の相性認識は広告業、仲介業など多くビジネスに利用することができます。*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CqrfuCaQ6P5"
      },
      "source": [
        "encoded_data = tokenizer.encode_plus(\n",
        "    '濃厚煮干スープが絶品！ 厳選した煮干・魚介と濃厚豚骨スープを合わせた「濃厚煮干中華そば」。',\n",
        "    text_pair='濃くのあるスープで、めちゃくちゃ美味いっ！！豚肉、穂先メンマも相変わらず抜群の美味さ。', \n",
        "    add_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpR8RxowSV3W"
      },
      "source": [
        "tokenizer.tokenize('濃厚煮干スープが絶品！ 厳選した煮干・魚介と濃厚豚骨スープを合わせた「濃厚煮干中華そば」。'),tokenizer.tokenize('濃くのあるスープで、めちゃくちゃ美味いっ！！豚肉、穂先メンマも相変わらず抜群の美味さ。')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrDf1mZRSg7Q"
      },
      "source": [
        "(['濃厚', '煮', '##干', 'スープ', 'が', '絶', '##品', '!', '厳', '##選', 'し', 'た', '煮', '##干', '・', '魚介', 'と', '濃厚', '豚', '骨', 'スープ', 'を', '合わせ', 'た', '「', '濃厚', '煮', '##干', '中華', 'そば', '」', '。']\n",
        "\n",
        " ['濃', '##く', 'の', 'ある', 'スープ', 'で', '、', 'め', '##ちゃ', '##く', '##ちゃ', '美味', 'いっ', '!!', '豚肉', '、', '穂', '##先', 'メン', '##マ', 'も', '相', '##変', '##わら', '##ず', '抜群', 'の', '美味', 'さ', '。'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YriKefdPSZwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "293a3ee5-7e0a-43f3-c0d7-92dc6210523c"
      },
      "source": [
        "encoded_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 24481, 9698, 29893, 14173, 14, 1814, 28728, 679, 2191, 28664, 15, 10, 9698, 29893, 35, 24035, 13, 24481, 10102, 2552, 14173, 11, 1943, 10, 36, 24481, 9698, 29893, 2725, 9313, 38, 8, 3, 3573, 28504, 5, 31, 14173, 12, 6, 2087, 7255, 28504, 7255, 18178, 1281, 3421, 26173, 6, 8174, 28947, 5470, 28523, 28, 423, 28801, 1747, 28700, 22947, 5, 18178, 26, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upzQaLK9UNoB"
      },
      "source": [
        "## **訓練のデータセットとデータ前処理**\n",
        "\n",
        "訓練データーセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9AvCl_0UWOD"
      },
      "source": [
        "[Textual Entailment 評価データ](http://nlp.ist.i.kyoto-u.ac.jp/edit.php?Textual%20Entailment%20%E8%A9%95%E4%BE%A1%E3%83%87%E3%83%BC%E3%82%BF)RTE(Recognizing Textual Entailment) -> 推論認識   \n",
        "\n",
        "内容を説明：\n",
        "\n",
        "* 有る文書の前提文で、有る仮説文は推論が成立かどうかを判定モデルです。　前提情報の文章が一つと仮説文が一つで、２つインプットがあり、結果は前提情報によって仮説の推論が成立かどうか判定する。つまり、アウトプットが一つで分類することです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Rv_yT5UdC_"
      },
      "source": [
        "### **PyTorchのBERTモデルにインプットするため、データ前処理する。**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIDAw6MBURSF"
      },
      "source": [
        "def xml2df(xml_data):\n",
        "    root = ET.XML(xml_data) # element tree\n",
        "    all_records = []\n",
        "    for i, child in enumerate(root):\n",
        "        record = {}\n",
        "        record['id'] = child.get('id')\n",
        "        record['label'] = child.get('label')\n",
        "        record['category'] = child.get('category')\n",
        "        for subchild in child:\n",
        "            record[subchild.tag] = subchild.text\n",
        "        all_records.append(record)\n",
        "    df = pd.DataFrame(all_records)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozrgC2ceg6TZ"
      },
      "source": [
        "import requests\n",
        "\n",
        "URL = \"http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/rte/entail_evaluation_set_label_conv.xml\"\n",
        "\n",
        "response = requests.get(URL)\n",
        "\n",
        "with open('feed.xml', 'wb') as file:\n",
        "    file.write(response.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk-eXR-0hRVq"
      },
      "source": [
        "text_xml = open('feed.xml').read()\n",
        "df = xml2df(text_xml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW570kg2UoO2"
      },
      "source": [
        "# load XML to dataframe\n",
        "#text_xml = open('Recognizing_Textual_Entailment_2.xml').read()\n",
        "#df = xml2df(text_xml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r6rowB_VXGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "357c5cd0-6c93-4af7-9fd5-4a41242d0390"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>もみじ狩りに行った。</td>\n",
              "      <td>狩りをした。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>ジョンは怠慢で、ビルは勤勉だ。</td>\n",
              "      <td>犬は怠慢で、人は勤勉だ。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>羽田に行った。</td>\n",
              "      <td>千葉に行った。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>英文法を勉強した。</td>\n",
              "      <td>中国語を勉強した。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>角館はみちのくの小京都である。</td>\n",
              "      <td>角館は京都である。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  id label      category               t1            t2  label_num\n",
              "0  0     N  語彙(体言):下位→上位       もみじ狩りに行った。        狩りをした。          0\n",
              "1  1     N  語彙(体言):下位→上位  ジョンは怠慢で、ビルは勤勉だ。  犬は怠慢で、人は勤勉だ。          0\n",
              "2  2     N  語彙(体言):下位→上位          羽田に行った。       千葉に行った。          0\n",
              "3  3     N  語彙(体言):下位→上位        英文法を勉強した。     中国語を勉強した。          0\n",
              "4  4     N  語彙(体言):下位→上位  角館はみちのくの小京都である。     角館は京都である。          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xADhkYMJVmtd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "474db227-95be-49ef-f794-d44ffb6aea0c"
      },
      "source": [
        "df.loc[df.label == 'N'].sample(5)[['label','t1','t2']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>N</td>\n",
              "      <td>根菜を使った。</td>\n",
              "      <td>レンコンを食べた。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>N</td>\n",
              "      <td>せんべいがしけっていて、残念だった。</td>\n",
              "      <td>せんべいはがっかりした。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064</th>\n",
              "      <td>N</td>\n",
              "      <td>松茸は人工栽培できないので、外国から輸入している。</td>\n",
              "      <td>日本人は松茸が好きだ。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>N</td>\n",
              "      <td>五羽の仔ウサギが産まれて、三羽が死んでしまった。</td>\n",
              "      <td>全部で8羽の仔ウサギがいる。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2428</th>\n",
              "      <td>N</td>\n",
              "      <td>壁のカレンダーに予定を書き込んでください。</td>\n",
              "      <td>机にカレンダーがある。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                         t1              t2\n",
              "92       N                    根菜を使った。       レンコンを食べた。\n",
              "1224     N         せんべいがしけっていて、残念だった。    せんべいはがっかりした。\n",
              "2064     N  松茸は人工栽培できないので、外国から輸入している。     日本人は松茸が好きだ。\n",
              "1845     N   五羽の仔ウサギが産まれて、三羽が死んでしまった。  全部で8羽の仔ウサギがいる。\n",
              "2428     N      壁のカレンダーに予定を書き込んでください。     机にカレンダーがある。"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH1zeMyKVrUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68c7e669-6d9a-4f76-9c36-70b81e6414a5"
      },
      "source": [
        "df.loc[df.label == 'Y'].sample(5)[['label','t1','t2']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Y</td>\n",
              "      <td>チョコレート工場の見学に行った。</td>\n",
              "      <td>工場見学に行った。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353</th>\n",
              "      <td>Y</td>\n",
              "      <td>権力と金と女が欲しい。</td>\n",
              "      <td>権力と金が欲しい。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>Y</td>\n",
              "      <td>パンにカビが生えていた。</td>\n",
              "      <td>パンは古かった。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2045</th>\n",
              "      <td>Y</td>\n",
              "      <td>太郎のおみやげは、ちんすこうだった。</td>\n",
              "      <td>太郎はお土産にちんすこうを買って来た。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Y</td>\n",
              "      <td>夫が風邪をひいた。</td>\n",
              "      <td>私は妻である。</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                  t1                   t2\n",
              "20       Y    チョコレート工場の見学に行った。            工場見学に行った。\n",
              "2353     Y         権力と金と女が欲しい。            権力と金が欲しい。\n",
              "1425     Y        パンにカビが生えていた。             パンは古かった。\n",
              "2045     Y  太郎のおみやげは、ちんすこうだった。  太郎はお土産にちんすこうを買って来た。\n",
              "499      Y           夫が風邪をひいた。              私は妻である。"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypIFpgo4VuVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6105841f-3ff1-4649-c586-92b6778d0642"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2472</td>\n",
              "      <td>2472</td>\n",
              "      <td>2472</td>\n",
              "      <td>2472</td>\n",
              "      <td>2472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2472</td>\n",
              "      <td>2</td>\n",
              "      <td>166</td>\n",
              "      <td>1295</td>\n",
              "      <td>2422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>570</td>\n",
              "      <td>Y</td>\n",
              "      <td>語彙(用言):言い換え</td>\n",
              "      <td>どうも具合が悪い。</td>\n",
              "      <td>亜硫酸の生成方法を知らなかった。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1586</td>\n",
              "      <td>250</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id label     category         t1                t2\n",
              "count   2472  2472         2472       2472              2472\n",
              "unique  2472     2          166       1295              2422\n",
              "top      570     Y  語彙(用言):言い換え  どうも具合が悪い。  亜硫酸の生成方法を知らなかった。\n",
              "freq       1  1586          250          7                 4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rz1AjARVwvd"
      },
      "source": [
        "df['label_num'] = df['label'].map({'Y': 1, 'N': 0})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ztARqd2Vy9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "225bca80-0a79-4863-f11d-23a192af4fd9"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>もみじ狩りに行った。</td>\n",
              "      <td>狩りをした。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>ジョンは怠慢で、ビルは勤勉だ。</td>\n",
              "      <td>犬は怠慢で、人は勤勉だ。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>羽田に行った。</td>\n",
              "      <td>千葉に行った。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>英文法を勉強した。</td>\n",
              "      <td>中国語を勉強した。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>N</td>\n",
              "      <td>語彙(体言):下位→上位</td>\n",
              "      <td>角館はみちのくの小京都である。</td>\n",
              "      <td>角館は京都である。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>2467</td>\n",
              "      <td>N</td>\n",
              "      <td>その他:名前</td>\n",
              "      <td>香と真樹が結婚した。</td>\n",
              "      <td>真樹は男性である。</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2468</th>\n",
              "      <td>2468</td>\n",
              "      <td>Y</td>\n",
              "      <td>その他:命名</td>\n",
              "      <td>ラッシュにぶつかった。</td>\n",
              "      <td>犬にぶつかった。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2469</th>\n",
              "      <td>2469</td>\n",
              "      <td>Y</td>\n",
              "      <td>その他|語彙(体言):定義的</td>\n",
              "      <td>ボジョレ・ヌーヴォーが解禁になった。</td>\n",
              "      <td>ボジョレ・ヌーヴォーの販売には解禁日がある。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2470</th>\n",
              "      <td>2470</td>\n",
              "      <td>Y</td>\n",
              "      <td>その他|構文:主語の変換</td>\n",
              "      <td>彼は英語が堪能である。</td>\n",
              "      <td>彼の英語はうまい。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2471</th>\n",
              "      <td>2471</td>\n",
              "      <td>Y</td>\n",
              "      <td>その他：照応</td>\n",
              "      <td>彼は、自分の家が炎上するのを、ただ眺めていた。</td>\n",
              "      <td>彼は、彼の家が炎上するのを、ただ眺めていた。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2472 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id label  ...                      t2 label_num\n",
              "0        0     N  ...                  狩りをした。         0\n",
              "1        1     N  ...            犬は怠慢で、人は勤勉だ。         0\n",
              "2        2     N  ...                 千葉に行った。         0\n",
              "3        3     N  ...               中国語を勉強した。         0\n",
              "4        4     N  ...               角館は京都である。         0\n",
              "...    ...   ...  ...                     ...       ...\n",
              "2467  2467     N  ...               真樹は男性である。         0\n",
              "2468  2468     Y  ...                犬にぶつかった。         1\n",
              "2469  2469     Y  ...  ボジョレ・ヌーヴォーの販売には解禁日がある。         1\n",
              "2470  2470     Y  ...               彼の英語はうまい。         1\n",
              "2471  2471     Y  ...  彼は、彼の家が炎上するのを、ただ眺めていた。         1\n",
              "\n",
              "[2472 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kIaew-kV0m6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "258b2854-ab8b-457b-ddb6-03dbe491173e"
      },
      "source": [
        "df.loc[0]['t1']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'もみじ狩りに行った。'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpSr7D_eV4zG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9abc3a0c-c2b8-45b0-af78-058862088fc6"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', df.loc[0]['t1'])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(df.loc[0]['t1']))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df.loc[0]['t1'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  もみじ狩りに行った。\n",
            "Tokenized:  ['もみ', '##じ', '狩り', 'に', '行っ', 'た', '。']\n",
            "Token IDs:  [23688, 28635, 11899, 7, 517, 10, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JBbJuOuV74X"
      },
      "source": [
        "encoded_data = tokenizer.encode_plus('もみじ狩りに行った。',text_pair='狩りをした。', add_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jrS5G1IV_i8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dcb8c242-93d0-4f09-a08f-64905d7dc6f7"
      },
      "source": [
        "encoded_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 23688, 28635, 11899, 7, 517, 10, 8, 3, 11899, 11, 15, 10, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH7yNdA4WBae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "dcd6d012-c0eb-4f32-a5f9-971c1bcd72ef"
      },
      "source": [
        "inputs = []\n",
        "labels = []\n",
        "for index, row in df.iterrows():\n",
        "    encoded_sent = tokenizer.encode_plus(row['t1'],text_pair=row['t2'], add_special_tokens=True)\n",
        "    inputs.append(encoded_sent)\n",
        "    labels.append(row['label_num'])\n",
        "\n",
        "print('Token IDs:', inputs[10])\n",
        "print('\\n',labels[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token IDs: {'input_ids': [2, 5250, 5, 73, 28614, 28528, 28764, 9, 6, 17172, 340, 28482, 205, 308, 10, 8, 3, 5250, 5, 73, 28614, 28528, 28764, 9, 6, 865, 28652, 308, 10, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            " 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMA3htSyWFNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df0edbe9-b43e-46fd-fe13-0428f5793ae4"
      },
      "source": [
        "len(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2472"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNHlDz9aWI2z"
      },
      "source": [
        "input_ids = []\n",
        "token_type_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for x in inputs:\n",
        "    input_ids.append(x[\"input_ids\"])\n",
        "    token_type_ids.append(x[\"token_type_ids\"])\n",
        "    attention_masks.append(x[\"attention_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWb6liVtbtLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a7a4934d-5b93-4921-d6d1-b781dc715154"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert-output-vector.png\tRecognizing_Textual_Entailment_2.xml\n",
            "feed.xml\t\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku81_rFIWPj9"
      },
      "source": [
        "#### データの補充と削除\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1ZFBMH1ED9oBbYyfXcVp3Jq-cT9VgJGsB)\n",
        "\n",
        "MAX LEN は50単語なので、64で設定すれば、問題がないと思います。\n",
        "\n",
        "もしインプットの長さが512個単語を超えたら、削除します。（後ろ削除か、中間に削除かなど）\n",
        "\n",
        "単語数が足りなくでも後ろ設定数までに0を補足します。\n",
        "\n",
        "Padding & Truncating!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geDFIkqrWLv_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "996dcfe2-52e4-4e2a-b36a-07b482a87c41"
      },
      "source": [
        "max([len(sen) for sen in input_ids])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRJNzxP0WZ3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bfda8035-a5d6-4bb9-a840-0e5458387011"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "#MAX_LEN = 50\n",
        "\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "token_type_ids = pad_sequences(token_type_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxH6NKmSW5R8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4c92696e-15a3-43b1-8034-06008fbbaffa"
      },
      "source": [
        "input_ids[0],token_type_ids[0],attention_masks[0],labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    2, 23688, 28635, 11899,     7,   517,    10,     8,     3,\n",
              "        11899,    11,    15,    10,     8,     3,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW4e0gNmXCwA"
      },
      "source": [
        "#### 訓練のデータセットを分割する。\n",
        "\n",
        "\n",
        "データセットを分割して、90％が訓練用です。10％が検証用です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGVDz0OyW8oq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the token_type.\n",
        "train_token_type, validation_token_type, _, _ = train_test_split(token_type_ids, labels,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                                       random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Lb4QX7XOnL"
      },
      "source": [
        "#### PyTorchのデータタイプに変換する\n",
        "\n",
        "Torch tensorsにインプットデータを変換する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma3nTfwNXIqW"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_token_type = torch.tensor(train_token_type)\n",
        "validation_token_type = torch.tensor(validation_token_type)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTfNihJHXUqM"
      },
      "source": [
        "Pytorch訓練データセットに生成する\n",
        "\n",
        "Pytorch検証データセットに生成する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQx9cX74XRMG"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "#batch_size = 16\n",
        "\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_token_type, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_token_type, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXxFZMplXc_U"
      },
      "source": [
        "## **Fine-Tuning the model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAhP0J2VXT2q"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"daigo/bert-base-japanese-sentiment\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNm6ELtQXZs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc0f7775-383f-4539-b3e7-1d67266fe585"
      },
      "source": [
        "# run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uo_HNkXiRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09f20656-dee7-4003-a982-7c1837affbef"
      },
      "source": [
        "model.get_input_embeddings()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32000, 768, padding_idx=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYsI4EsmXlz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "f0fcf015-a717-4cb1-e7a5-a9cc3bed1112"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (32000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJIMj_ctXy-S"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-DuuQEX2pF"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "#epochs = 4\n",
        "#epochs = 8\n",
        "epochs = 10\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umrIfkgrX5O3"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJp3McntX7Yn"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KOD9LBmX-IW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7525f9c-c491-46c6-8bf5-b43b70fd0ac0"
      },
      "source": [
        "train_dataloader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f73433d97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9-JSqb6YDdo"
      },
      "source": [
        "### ビジネスのタスクに新しいモデルの学習\n",
        "\n",
        "\n",
        "transformersのドキュメントページ：\n",
        "https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0tRSt2KYAII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a07cf591-c521-45ed-fd1b-3f3c9f09ba9c"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # `batch` contains four pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: train token type\n",
        "        #   [2]: attention masks\n",
        "        #   [3]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_train_token_type = batch[1].to(device)\n",
        "        b_input_mask = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=b_train_token_type, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_train_token_type, b_input_mask, b_labels = batch\n",
        "        \n",
        "        #print('data:',b_input_ids,'\\n',b_train_token_type,'\\n',b_input_mask)\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=b_train_token_type, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.68\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of     70.    Elapsed: 0:00:08.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:00:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOi3mQnYHhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "52588095-875e-4cd8-fe20-3c1c041d1f15"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uCjUsf9YQo6"
      },
      "source": [
        "## **モデルの性能を検証**\n",
        "\n",
        "\n",
        "検証ファンクションを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1CFiuR3YSEU"
      },
      "source": [
        "def rte_function(text,text2):\n",
        "\n",
        "    t_inputs = tokenizer.encode_plus(text,text_pair=text2, add_special_tokens=True)\n",
        "    \n",
        "    t_input_ids = pad_sequences([t_inputs[\"input_ids\"]], maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "    t_token_type_ids = pad_sequences([t_inputs[\"token_type_ids\"]], maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "    t_attention_mask = pad_sequences([t_inputs[\"attention_mask\"]], maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "    \n",
        "    t_input_ids = torch.tensor(t_input_ids[0]).unsqueeze(0)\n",
        "    t_token_type_ids = torch.tensor(t_token_type_ids[0]).unsqueeze(0)\n",
        "    t_attention_mask = torch.tensor(t_attention_mask[0]).unsqueeze(0)\n",
        "\n",
        "    t_input_ids = t_input_ids.to(device)\n",
        "    t_token_type_ids = t_token_type_ids.to(device)\n",
        "    t_attention_mask = t_attention_mask.to(device)\n",
        "    \n",
        "    with torch.no_grad():    \n",
        "        outputs = model(t_input_ids, token_type_ids=t_token_type_ids, attention_mask=t_attention_mask)\n",
        "    \n",
        "    ng = outputs[0][0][0].item()\n",
        "    ok = outputs[0][0][1].item()\n",
        "    ng_p = np.exp(ng)/(np.exp(ng)+np.exp(ok))\n",
        "    ok_p = np.exp(ok)/(np.exp(ng)+np.exp(ok))\n",
        "    \n",
        "    if ng_p>=ok_p:\n",
        "        result = {\"label\" : \"元の情報からの仮説は推測が成立しません。\",\"score\" : ng_p}\n",
        "    else:\n",
        "        result = {\"label\" : \"元の情報からの仮説は推測が成立です。\",\"score\" : ok_p}\n",
        "        \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWnWV62SYd20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e3d273a-bef1-4cd6-dfcf-a10526646724"
      },
      "source": [
        "# 情報源の文章\n",
        "premise = '避難訓練があった。'\n",
        "# 仮説\n",
        "hypothesis = '災害時を想定している。'\n",
        "\n",
        "\n",
        "# 仮説について、推論成立かどうか判定\n",
        "rte_function(premise,hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '元の情報からの仮説は推測が成立です。', 'score': 0.9972688753667335}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w2E4lx5YVvO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fd6defc-1145-4df7-c28a-14a2e5729d3e"
      },
      "source": [
        "# 情報源の文章\n",
        "premise = '今日は浴衣姿の人が多い。'\n",
        "# 仮説\n",
        "hypothesis = '花火大会がある。'\n",
        "\n",
        "\n",
        "# 仮説について、推論成立かどうか判定\n",
        "rte_function(premise,hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '元の情報からの仮説は推測が成立しません。', 'score': 0.9919223189238091}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNaRRPlNYZMF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61c2d431-bb2c-4a75-e4d1-4888c220e64e"
      },
      "source": [
        "# 情報源の文章\n",
        "premise = '太郎は次郎より背が高い。'\n",
        "# 仮説\n",
        "hypothesis = '次郎は太郎より背が低い。'\n",
        "\n",
        "\n",
        "# 仮説について、推論成立かどうか判定\n",
        "rte_function(premise,hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': '元の情報からの仮説は推測が成立です。', 'score': 0.9254253411265165}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpdEadonli3Z"
      },
      "source": [
        "## **訓練した自然言語モデルを保存する**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f5Yi8jmYgZF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64b2596c-d795-410d-cdf3-2136c550b41d"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = './sa_model_save/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model \n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./sa_model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./sa_model_save/vocab.txt',\n",
              " './sa_model_save/special_tokens_map.json',\n",
              " './sa_model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0shzjYAl5Kj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64a7fa84-533d-4801-b163-31a1ebbe6d09"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access './model_save/pytorch_model.bin': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUuuS5jhm_IO"
      },
      "source": [
        "Colabノートブックを閉じる前に、訓練したのモデルをロカール或いはGoogle Driveにダンロードします。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY96mUsnmfDZ"
      },
      "source": [
        "!cp -r ./model_save/ \"./drive/a directory in your Google Drive/BERT Fine-Tuning/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUXvBphcmwUr"
      },
      "source": [
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}